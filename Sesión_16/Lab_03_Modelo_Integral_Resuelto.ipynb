{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9526f0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "903ed659",
   "metadata": {},
   "source": [
    "Laboratorio 03: Modelo Integral de ML para Operaciones Petroleras\n",
    "==================================================================\n",
    "\n",
    "Objetivo: Combinar predicción y clasificación para crear un sistema integral\n",
    "          de monitoreo y predicción para operaciones petroleras.\n",
    "\n",
    "Tareas:\n",
    "1. Integrar datos de múltiples fuentes\n",
    "2. Crear pipeline de ML completo\n",
    "3. Implementar predicción de producción Y detección de eventos\n",
    "4. Generar dashboard de resultados\n",
    "5. Crear sistema de recomendaciones automatizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c405484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABORATORIO 03: MODELO INTEGRAL DE ML\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"LABORATORIO 03: MODELO INTEGRAL DE ML\")\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ad1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAREA 1: Integrar datos de múltiples fuentes\n",
      "----------------------------------------\n",
      "Dataset integrado: (500, 18)\n",
      "       fecha   well_id  presion_boca_psi  temperatura_f  dias_operacion  \\\n",
      "0 2024-04-14  POZO-003            1488.9          196.1               1   \n",
      "1 2024-04-15  POZO-003            1410.7          158.2               2   \n",
      "2 2024-04-16  POZO-001            1420.1          204.2               3   \n",
      "3 2024-04-17  POZO-001            1534.1          201.7               4   \n",
      "4 2024-04-18  POZO-003            1347.6          181.9               5   \n",
      "\n",
      "   choke_size  produccion_oil_bbl  produccion_gas_mcf  produccion_agua_bbl  \\\n",
      "0          28              1447.5               728.5                424.9   \n",
      "1          36              1536.7               805.5                473.3   \n",
      "2          32              1577.8               803.4                478.4   \n",
      "3          28              1481.8               748.0                459.5   \n",
      "4          32              1526.6               766.8                468.5   \n",
      "\n",
      "   presion_fondo_psi  presion_cabeza_psi  temperatura_fondo_f  \\\n",
      "0                NaN                 NaN                  NaN   \n",
      "1            2159.68             1309.65               193.12   \n",
      "2                NaN                 NaN                  NaN   \n",
      "3                NaN                 NaN                  NaN   \n",
      "4                NaN                 NaN                  NaN   \n",
      "\n",
      "   flujo_total_bpd  corte_agua_pct  gor_scf_bbl  indice_productividad  \\\n",
      "0              NaN             NaN          NaN                   NaN   \n",
      "1          1331.48           25.22       504.84                  9.68   \n",
      "2              NaN             NaN          NaN                   NaN   \n",
      "3              NaN             NaN          NaN                   NaN   \n",
      "4              NaN             NaN          NaN                   NaN   \n",
      "\n",
      "   dias_desde_mantenimiento  horas_operacion_continua  \n",
      "0                       NaN                       NaN  \n",
      "1                      63.0                     595.0  \n",
      "2                       NaN                       NaN  \n",
      "3                       NaN                       NaN  \n",
      "4                       NaN                       NaN  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_34821/2882328151.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m \n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Aplicar ingeniería de features temporal\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m df_procesado = crear_features_temporales(df_integrado) \u001b[38;5;28;01mif\u001b[39;00m df_integrado \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1575\u001b[39m     @final\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m         raise ValueError(\n\u001b[32m   1578\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1579\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1580\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# TAREA 1: Integración de datos\n",
    "# ==============================\n",
    "print(\"\\nTAREA 1: Integrar datos de múltiples fuentes\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# TO DO: Cargar y combinar datasets\n",
    "df_produccion = pd.read_csv('/workspaces/CursoPython-Basico-JuanDavid/Sesión_16/datos/produccion_historica.csv')\n",
    "df_eventos = pd.read_csv('/workspaces/CursoPython-Basico-JuanDavid/Sesión_16/datos/eventos_operacionales.csv')\n",
    "df_parametros = pd.read_csv('/workspaces/CursoPython-Basico-JuanDavid/Sesión_16/datos/parametros_pozos.csv')\n",
    "\n",
    "# TO DO: Realizar merge de los datasets. \n",
    "\n",
    "# Usar fecha y well_id como claves\n",
    "\n",
    "def safe_to_datetime(s, fmt=None):\n",
    "    \"\"\"Convierte a datetime de manera segura (devuelve NaT si falla).\"\"\"\n",
    "    if fmt:\n",
    "        return pd.to_datetime(s, format=fmt, errors='coerce')\n",
    "    return pd.to_datetime(s, errors='coerce')\n",
    "\n",
    "df_produccion['fecha'] = safe_to_datetime(df_produccion['fecha'])\n",
    "df_eventos['fecha'] = safe_to_datetime(df_eventos['fecha'])\n",
    "df_parametros['fecha'] = safe_to_datetime(df_parametros['fecha'])\n",
    "\n",
    "# Unimos producción y eventos por 'fecha' y 'well_id'\n",
    "#df_merged = pd.merge(df_produccion, df_eventos, on=['fecha', 'well_id'], how='left')\n",
    "\n",
    "#print(df_merged.head())\n",
    "\n",
    "# Unimos parámetros de pozos por 'well_id'\n",
    "#df_integrado = pd.merge(df_merged, df_parametros, on='well_id', how='left')\n",
    "\n",
    "# Homogeneizar columnas clave\n",
    "for dfx in (df_produccion, df_parametros):\n",
    "    dfx['well_id'] = dfx['well_id'].astype(str)\n",
    "\n",
    "# Merge principal a nivel diario por well_id + fecha\n",
    "df_integrado = (\n",
    "    pd.merge(df_produccion, df_parametros, on=['fecha', 'well_id'], how='left', suffixes=('', '_param'))\n",
    ")\n",
    "\n",
    "print(f\"Dataset integrado: {df_integrado.shape if df_integrado is not None else 'No creado'}\")\n",
    "#info_df(df_integrado, \"df_integrado (preview)\")\n",
    "\n",
    "\n",
    "print(df_integrado.head())\n",
    "\n",
    "# TO DO: Crear features temporales\n",
    "def crear_features_temporales(df):\n",
    "    \"\"\"\n",
    "    Crea features basadas en tiempo\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # TO DO: Extraer componentes de fecha\n",
    "    df['dia_semana'] = pd.to_datetime(df['fecha']).dt.dayofweek\n",
    "    df['mes'] = pd.to_datetime(df['fecha']).dt.month\n",
    "    df['trimestre'] = pd.to_datetime(df['fecha']).dt.quarter\n",
    "    \n",
    "    # TO DO: Crear features de ventanas móviles\n",
    "    df['prod_promedio_7d'] = df['produccion_oil_bbl'].rolling(7).mean()\n",
    "    df['prod_std_7d'] = df['produccion_oil_bbl'].rolling(7).std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar ingeniería de features temporal\n",
    "df_procesado = crear_features_temporales(df_integrado) if df_integrado else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAREA 2: Crear pipeline de ML\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TAREA 2: Pipeline de preparación\n",
    "# =================================\n",
    "print(\"\\nTAREA 2: Crear pipeline de ML\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Definir features para cada modelo\n",
    "features_produccion = [\n",
    "    'presion_boca_psi', 'temperatura_f', 'dias_operacion',\n",
    "    'choke_size', 'prod_promedio_7d', 'mes', 'trimestre'\n",
    "]\n",
    "\n",
    "features_eventos = [\n",
    "    'temperatura', 'vibracion', 'presion', 'ruido_db',\n",
    "    'dias_desde_mantenimiento', 'horas_operacion_continua'\n",
    "]\n",
    "\n",
    "# TO DO: Crear pipelines para cada modelo\n",
    "def crear_pipeline_produccion():\n",
    "    \"\"\"\n",
    "    Pipeline para predicción de producción\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('modelo', RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def crear_pipeline_eventos():\n",
    "    \"\"\"\n",
    "    Pipeline para clasificación de eventos\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('modelo', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# Crear los pipelines\n",
    "pipeline_produccion = crear_pipeline_produccion()\n",
    "pipeline_eventos = crear_pipeline_eventos()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAREA 3: Entrenar modelos\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_procesado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# TO DO: Preparar datos para modelo de producción\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_procesado\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Eliminar filas con NaN en features críticas\u001b[39;00m\n\u001b[32m      9\u001b[39m     df_prod = df_procesado.dropna(subset=features_produccion + [\u001b[33m'\u001b[39m\u001b[33mproduccion_oil_bbl\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     10\u001b[39m     X_prod = df_prod[features_produccion]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_procesado' is not defined"
     ]
    }
   ],
   "source": [
    "# TAREA 3: Entrenamiento de modelos\n",
    "# ==================================\n",
    "print(\"\\nTAREA 3: Entrenar modelos\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# TO DO: Preparar datos para modelo de producción\n",
    "if df_procesado is not None:\n",
    "    # Eliminar filas con NaN en features críticas\n",
    "    df_prod = df_procesado.dropna(subset=features_produccion + ['produccion_oil_bbl'])\n",
    "    X_prod = df_prod[features_produccion]\n",
    "    y_prod = df_prod['produccion_oil_bbl']\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_prod_train, X_prod_test, y_prod_train, y_prod_test = train_test_split(\n",
    "        X_prod, y_prod, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # TO DO: Entrenar modelo de producción\n",
    "    pipeline_produccion.fit(X_prod_train, y_prod_train)\n",
    "    \n",
    "    # TO DO: Validación cruzada\n",
    "    scores = cross_val_score(pipeline_produccion, X_prod_train, y_prod_train, \n",
    "                              cv=5, scoring='neg_mean_absolute_error')\n",
    "    print(f\"MAE promedio (CV): {-scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "\n",
    "# TODO: Preparar datos para modelo de eventos\n",
    "if df_procesado is not None:\n",
    "    df_eventos = df_procesado.dropna(subset=features_eventos + ['tipo_evento'])\n",
    "    X_eventos = df_eventos[features_eventos]\n",
    "    y_eventos = df_eventos['tipo_evento']\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_eventos_train, X_eventos_test, y_eventos_train, y_eventos_test = train_test_split(\n",
    "        X_eventos, y_eventos, test_size=0.2, stratify=y_eventos, random_state=42\n",
    "    )\n",
    "    \n",
    "    # TO DO: Entrenar modelo de eventos\n",
    "    pipeline_eventos.fit(X_eventos_train, y_eventos_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAREA 4: Evaluación integral\n",
    "# =============================\n",
    "print(\"\\nTAREA 4: Evaluación integral del sistema\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# TO DO: Evaluar modelo de producción\n",
    "print(\"Modelo de Producción:\")\n",
    "if 'X_prod_test' in locals():\n",
    "    y_pred_prod = pipeline_produccion.predict(X_prod_test)\n",
    "    mae = mean_absolute_error(y_prod_test, y_pred_prod)\n",
    "    mape = np.mean(np.abs((y_prod_test - y_pred_prod) / y_prod_test)) * 100\n",
    "    print(f\"  MAE: {mae:.2f} bbl\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    pass\n",
    "\n",
    "# TO DO: Evaluar modelo de eventos\n",
    "print(\"\\nModelo de Eventos:\")\n",
    "if 'X_eventos_test' in locals():\n",
    "    y_pred_eventos = pipeline_eventos.predict(X_eventos_test)\n",
    "    print(classification_report(y_eventos_test, y_pred_eventos))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAREA 5: Dashboard de resultados\n",
    "# =================================\n",
    "print(\"\\nTAREA 5: Crear dashboard de resultados\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Layout del dashboard\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Panel 1: Predicción de producción (serie temporal)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "# TO DO: Graficar predicciones vs reales para últimos 30 días\n",
    "ax1.set_title('Predicción de Producción - Últimos 30 días', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Días')\n",
    "ax1.set_ylabel('Producción (bbl)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Métricas de producción\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "# TO DO: Mostrar métricas clave\n",
    "metricas_texto = \"\"\"\n",
    "MÉTRICAS DE PRODUCCIÓN\n",
    "━━━━━━━━━━━━━━━━━\n",
    "MAE: XXX bbl\n",
    "MAPE: XX.X%\n",
    "R²: X.XXX\n",
    "\n",
    "Predicción promedio:\n",
    "XXXX bbl/día\n",
    "\n",
    "Tendencia: ↑ +X.X%\n",
    "\"\"\"\n",
    "ax2.text(0.1, 0.5, metricas_texto, fontsize=10, family='monospace')\n",
    "ax2.set_title('KPIs de Producción', fontsize=12, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Panel 3: Matriz de confusión de eventos\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "# TO DO: Mostrar matriz de confusión\n",
    "ax3.set_title('Clasificación de Eventos', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Panel 4: Distribución de eventos predichos\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "# TO DO: Pie chart o barplot de tipos de eventos\n",
    "ax4.set_title('Distribución de Eventos', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Panel 5: Importancia de features\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "# TO DO: Mostrar top 5 features más importantes\n",
    "ax5.set_title('Features Más Importantes', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Panel 6: Análisis de tendencias\n",
    "ax6 = fig.add_subplot(gs[2, :2])\n",
    "# TO DO: Mostrar tendencias de producción y eventos\n",
    "ax6.set_title('Análisis de Tendencias', fontsize=12, fontweight='bold')\n",
    "ax6.set_xlabel('Tiempo')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 7: Recomendaciones\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "recomendaciones = \"\"\"\n",
    "RECOMENDACIONES\n",
    "━━━━━━━━━━━━━━\n",
    "✓ Optimizar choke size\n",
    "  Impacto: +5% prod.\n",
    "\n",
    "⚠ Mantenimiento preventivo\n",
    "  Pozo #3 en 48hrs\n",
    "\n",
    "✓ Ajustar presión\n",
    "  Target: 1450 psi\n",
    "\n",
    "⚠ Revisar sensor temp.\n",
    "  Lecturas anómalas\n",
    "\"\"\"\n",
    "ax7.text(0.1, 0.5, recomendaciones, fontsize=9, family='monospace')\n",
    "ax7.set_title('Acciones Recomendadas', fontsize=12, fontweight='bold')\n",
    "ax7.axis('off')\n",
    "\n",
    "plt.suptitle('DASHBOARD INTEGRAL - SISTEMA ML PETROLERO', fontsize=16, fontweight='bold')\n",
    "plt.savefig('dashboard_ml_integral.png', dpi=100, bbox_inches='tight')\n",
    "print(\"Dashboard guardado como 'dashboard_ml_integral.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAREA 6: Sistema de recomendaciones\n",
    "# ====================================\n",
    "print(\"\\nTAREA 6: Sistema de recomendaciones automatizado\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def generar_recomendaciones(predicciones_prod, predicciones_eventos, parametros_actuales):\n",
    "    \"\"\"\n",
    "    Genera recomendaciones basadas en las predicciones\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    predicciones_prod : array\n",
    "        Predicciones de producción\n",
    "    predicciones_eventos : array\n",
    "        Predicciones de eventos\n",
    "    parametros_actuales : dict\n",
    "        Parámetros operacionales actuales\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    list : Lista de recomendaciones priorizadas\n",
    "    \"\"\"\n",
    "    recomendaciones = []\n",
    "    \n",
    "    # TO DO: Analizar tendencia de producción\n",
    "    if len(predicciones_prod) > 7:\n",
    "        tendencia = np.polyfit(range(7), predicciones_prod[-7:], 1)[0]\n",
    "        if tendencia < -10:  # Caída significativa\n",
    "            recomendaciones.append({\n",
    "                'prioridad': 'ALTA',\n",
    "                'tipo': 'PRODUCCIÓN',\n",
    "                'accion': 'Revisar parámetros operacionales',\n",
    "                'impacto': f'Caída de {abs(tendencia):.1f} bbl/día detectada'\n",
    "            })\n",
    "    \n",
    "    # TO DO: Analizar eventos predichos\n",
    "    eventos_criticos = ['falla_bomba', 'obstruccion', 'fuga']\n",
    "    for evento in predicciones_eventos:\n",
    "        if evento in eventos_criticos:\n",
    "            recomendaciones.append({\n",
    "                'prioridad': 'CRÍTICA',\n",
    "                'tipo': 'MANTENIMIENTO',\n",
    "                'accion': f'Intervención inmediata - {evento} detectado',\n",
    "                'impacto': 'Prevenir parada no planificada'\n",
    "            })\n",
    "    \n",
    "    # TO DO: Optimización de parámetros\n",
    "    if parametros_actuales.get('presion_boca_psi', 0) < 1200:\n",
    "        recomendaciones.append({\n",
    "            'prioridad': 'MEDIA',\n",
    "            'tipo': 'OPTIMIZACIÓN',\n",
    "            'accion': 'Aumentar presión de boca',\n",
    "            'impacto': 'Potencial aumento de 3-5% en producción'\n",
    "        })\n",
    "    \n",
    "    return sorted(recomendaciones, key=lambda x: \n",
    "                 {'CRÍTICA': 0, 'ALTA': 1, 'MEDIA': 2}.get(x['prioridad'], 3))\n",
    "\n",
    "# TO DO: Probar el sistema de recomendaciones\n",
    "parametros_ejemplo = {\n",
    "    'presion_boca_psi': 1100,\n",
    "    'temperatura_f': 185,\n",
    "    'choke_size': 30\n",
    "}\n",
    "\n",
    "predicciones_prod_ejemplo = np.array([1000, 980, 960, 940, 920, 900, 880])\n",
    "predicciones_eventos_ejemplo = ['normal', 'normal', 'falla_bomba']\n",
    "\n",
    "recomendaciones = generar_recomendaciones(\n",
    "    predicciones_prod_ejemplo,\n",
    "    predicciones_eventos_ejemplo,\n",
    "    parametros_ejemplo\n",
    ")\n",
    "\n",
    "print(\"\\nRECOMENDACIONES GENERADAS:\")\n",
    "print(\"=\" * 40)\n",
    "for i, rec in enumerate(recomendaciones, 1):\n",
    "    print(f\"\\n{i}. [{rec['prioridad']}] {rec['tipo']}\")\n",
    "    print(f\"   Acción: {rec['accion']}\")\n",
    "    print(f\"   Impacto: {rec['impacto']}\")\n",
    "\n",
    "\n",
    "# ANÁLISIS ROI\n",
    "# ============\n",
    "print(\"\\n\" + \"=\" * 55)\n",
    "print(\"ANÁLISIS DE RETORNO DE INVERSIÓN (ROI)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def calcular_roi_ml(mejora_produccion_pct=5, reduccion_fallas_pct=30, \n",
    "                     costo_implementacion=50000):\n",
    "    \"\"\"\n",
    "    Calcula el ROI de implementar el sistema ML\n",
    "    \"\"\"\n",
    "    # Supuestos\n",
    "    produccion_diaria_bbl = 1000\n",
    "    precio_barril = 75\n",
    "    dias_año = 365\n",
    "    costo_falla_dia = 500000\n",
    "    fallas_año_sin_ml = 6\n",
    "    \n",
    "    # Beneficios\n",
    "    ganancia_produccion = (produccion_diaria_bbl * mejora_produccion_pct/100 * \n",
    "                          precio_barril * dias_año)\n",
    "    \n",
    "    fallas_evitadas = fallas_año_sin_ml * reduccion_fallas_pct/100\n",
    "    ahorro_fallas = fallas_evitadas * costo_falla_dia\n",
    "    \n",
    "    beneficio_total = ganancia_produccion + ahorro_fallas\n",
    "    \n",
    "    # ROI\n",
    "    roi = ((beneficio_total - costo_implementacion) / costo_implementacion) * 100\n",
    "    payback_meses = (costo_implementacion / (beneficio_total / 12))\n",
    "    \n",
    "    print(f\"Análisis ROI del Sistema ML:\")\n",
    "    print(f\"  Inversión inicial: ${costo_implementacion:,}\")\n",
    "    print(f\"  Ganancia por producción: ${ganancia_produccion:,.0f}/año\")\n",
    "    print(f\"  Ahorro por prevención: ${ahorro_fallas:,.0f}/año\")\n",
    "    print(f\"  Beneficio total anual: ${beneficio_total:,.0f}\")\n",
    "    print(f\"  ROI: {roi:.1f}%\")\n",
    "    print(f\"  Período de recuperación: {payback_meses:.1f} meses\")\n",
    "    \n",
    "    return roi\n",
    "\n",
    "# Calcular ROI\n",
    "roi_sistema = calcular_roi_ml()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
